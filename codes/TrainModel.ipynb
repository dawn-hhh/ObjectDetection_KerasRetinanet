{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPU Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "if 'tensorflow' == K.backend():\n",
    "    import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "GPUconfig = tf.ConfigProto()\n",
    "GPUconfig.gpu_options.allow_growth = True\n",
    "GPUconfig.gpu_options.visible_device_list = '1'\n",
    "set_session(tf.Session(config=GPUconfig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet import layers  # noqa: F401\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "from keras_retinanet.preprocessing.kitti import KittiGenerator\n",
    "from keras_retinanet.preprocessing.open_images import OpenImagesGenerator\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.utils.anchors import make_shapes_callback\n",
    "from keras_retinanet.utils.config import read_config_file, parse_anchor_parameters\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras_retinanet.utils.model import freeze as freeze_model\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.anchors import AnchorParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makedirs(path):\n",
    "    # Intended behavior: try to create the directory,\n",
    "    # pass if the directory exists already, fails otherwise.\n",
    "    # Meant for Python 2.7/3.n compatibility.\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    \"\"\" Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "\n",
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    \"\"\" Load weights for model.\n",
    "\n",
    "    Args\n",
    "        model         : The model to load weights for.\n",
    "        weights       : The weights to load.\n",
    "        skip_mismatch : If True, skips layers whose shape of weights doesn't match with the model.\n",
    "    \"\"\"\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0,\n",
    "                  freeze_backbone=False, lr=1e-4, config=None):\n",
    "    \"\"\" Creates three models (model, training_model, prediction_model).\n",
    "\n",
    "    Args\n",
    "        backbone_retinanet : A function to call to create a retinanet model with a given backbone.\n",
    "        num_classes        : The number of classes to train.\n",
    "        weights            : The weights to load into the model.\n",
    "        multi_gpu          : The number of GPUs to use for training.\n",
    "        freeze_backbone    : If True, disables learning for the backbone.\n",
    "        config             : Config parameters, None indicates the default configuration.\n",
    "\n",
    "    Returns\n",
    "        model            : The base model. This is also the model that is saved in snapshots.\n",
    "        training_model   : The training model. If multi_gpu=0, this is identical to model.\n",
    "        prediction_model : The model wrapped with utility functions to perform object detection (applies regression values and performs NMS).\n",
    "    \"\"\"\n",
    "\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # load anchor parameters, or pass None (so that defaults will be used)\n",
    "    anchor_params = None\n",
    "    num_anchors   = None\n",
    "    #if config and 'anchor_parameters' in config:\n",
    "    if config:\n",
    "        ratios,scales,sizes,strides = config\n",
    "        anchor_params = AnchorParameters(sizes, strides, ratios, scales)\n",
    "        num_anchors   = anchor_params.num_anchors()\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        from keras.utils import multi_gpu_model\n",
    "        with tf.device('/cpu:1'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=lr, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model\n",
    "\n",
    "\n",
    "def create_callbacks(model, training_model, prediction_model, validation_generator, tensorboard_dir, evaluation, dataset_type, weighted_average, snapshots, snapshot_path, backbone_name):\n",
    "    \"\"\" Creates the callbacks to use during training.\n",
    "\n",
    "    Args\n",
    "        model: The base model.\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    tensorboard_callback = None\n",
    "\n",
    "    if tensorboard_dir:\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir                = tensorboard_dir,\n",
    "            histogram_freq         = 0,\n",
    "            batch_size             = batch_size,\n",
    "            write_graph            = True,\n",
    "            write_grads            = False,\n",
    "            write_images           = False,\n",
    "            embeddings_freq        = 0,\n",
    "            embeddings_layer_names = None,\n",
    "            embeddings_metadata    = None\n",
    "        )\n",
    "        callbacks.append(tensorboard_callback)\n",
    "\n",
    "    if evaluation and validation_generator:\n",
    "        if dataset_type == 'coco':\n",
    "            from ..callbacks.coco import CocoEval\n",
    "\n",
    "            # use prediction model for evaluation\n",
    "            evaluation = CocoEval(validation_generator, tensorboard=tensorboard_callback)\n",
    "        else:\n",
    "            evaluation = Evaluate(validation_generator, tensorboard=tensorboard_callback, weighted_average=weighted_average)\n",
    "        evaluation = RedirectModel(evaluation, prediction_model)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "    if snapshots:\n",
    "        # ensure directory created first; otherwise h5py will error after epoch.\n",
    "        makedirs(snapshot_path)\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(\n",
    "                snapshot_path,\n",
    "                '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=backbone_name, dataset_type=dataset_type)\n",
    "            ),\n",
    "            verbose=1,\n",
    "            # save_best_only=True,\n",
    "            # monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        checkpoint = RedirectModel(checkpoint, model)\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor    = 'loss',\n",
    "        factor     = 0.1,\n",
    "        patience   = 2,\n",
    "        verbose    = 1,\n",
    "        mode       = 'auto',\n",
    "        min_delta  = 0.0001,\n",
    "        cooldown   = 0,\n",
    "        min_lr     = 0\n",
    "    ))\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def create_generators(dataset_type, batch_size, config, image_min_side, image_max_side, preprocess_image):\n",
    "    \"\"\" Create generators for training and validation.\n",
    "\n",
    "    Args\n",
    "        args             : parseargs object containing configuration for generators.\n",
    "        preprocess_image : Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size'       : batch_size,\n",
    "        'config'           : config,\n",
    "        'image_min_side'   : image_min_side,\n",
    "        'image_max_side'   : image_max_side,\n",
    "        'preprocess_image' : preprocess_image,\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if random_transform:\n",
    "        transform_generator = random_transform_generator(\n",
    "            min_rotation=-0.1,\n",
    "            max_rotation=0.1,\n",
    "            min_translation=(-0.1, -0.1),\n",
    "            max_translation=(0.1, 0.1),\n",
    "            min_shear=-0.1,\n",
    "            max_shear=0.1,\n",
    "            min_scaling=(0.9, 0.9),\n",
    "            max_scaling=(1.1, 1.1),\n",
    "            flip_x_chance=0.5,\n",
    "            flip_y_chance=0.5,\n",
    "        )\n",
    "    else:\n",
    "        transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "\n",
    "    if dataset_type == 'coco':\n",
    "        # import here to prevent unnecessary dependency on cocoapi\n",
    "        from ..preprocessing.coco import CocoGenerator\n",
    "\n",
    "        train_generator = CocoGenerator(\n",
    "            coco_path,\n",
    "            'train2017',\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = CocoGenerator(\n",
    "            coco_path,\n",
    "            'val2017',\n",
    "            **common_args\n",
    "        )\n",
    "    elif dataset_type == 'pascal':\n",
    "        train_generator = PascalVocGenerator(\n",
    "            pascal_path,\n",
    "            'trainval',\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = PascalVocGenerator(\n",
    "            pascal_path,\n",
    "            'test',\n",
    "            **common_args\n",
    "        )\n",
    "    elif dataset_type == 'csv':\n",
    "        train_generator = CSVGenerator(\n",
    "            annotations,\n",
    "            classes,\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        if val_annotations:\n",
    "            validation_generator = CSVGenerator(\n",
    "                val_annotations,\n",
    "                classes,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "    elif dataset_type == 'oid':\n",
    "        train_generator = OpenImagesGenerator(\n",
    "            main_dir,\n",
    "            subset='train',\n",
    "            version=version,\n",
    "            labels_filter=labels_filter,\n",
    "            annotation_cache_dir=annotation_cache_dir,\n",
    "            parent_label=parent_label,\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = OpenImagesGenerator(\n",
    "            main_dir,\n",
    "            subset='validation',\n",
    "            version=version,\n",
    "            labels_filter=labels_filter,\n",
    "            annotation_cache_dir=annotation_cache_dir,\n",
    "            parent_label=parent_label,\n",
    "            **common_args\n",
    "        )\n",
    "    elif dataset_type == 'kitti':\n",
    "        train_generator = KittiGenerator(\n",
    "            kitti_path,\n",
    "            subset='train',\n",
    "            transform_generator=transform_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = KittiGenerator(\n",
    "            kitti_path,\n",
    "            subset='val',\n",
    "            **common_args\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'csv'\n",
    "backbone_name = 'resnet50'\n",
    "annotations = '' # path to train data csv file\n",
    "classes = '' # path to class label csv file\n",
    "\n",
    "batch_size = 8 #original = 4\n",
    "epochs = 30 #original = 30\n",
    "steps = 110 #original = 87\n",
    "image_min_side = 800\n",
    "image_max_side = 1333\n",
    "\n",
    "config = None\n",
    "random_transform = True\n",
    "\n",
    "#Setup validation:\n",
    "#evaluation = False\n",
    "#val_annotations = None\n",
    "#compute_val_loss = False\n",
    "evaluation = True\n",
    "val_annotations = '' # path to validation data csv file\n",
    "compute_val_loss = True\n",
    "\n",
    "snapshot = None\n",
    "snapshots = False #disable saving snapshots\n",
    "snapshot_path = './snapshots'\n",
    "weights = None\n",
    "imagenet_weights = True\n",
    "no_weights = False\n",
    "multi_gpu = 0\n",
    "freeze_backbone = True\n",
    "lr = 1e-4\n",
    "tensorboard_dir = './logs'\n",
    "weighted_average = True\n",
    "workers = 1\n",
    "max_queue_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Anchors (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default Anchor Settings:\n",
    "# sizes   = [32, 64, 128, 256, 512]\n",
    "# strides = [8, 16, 32, 64, 128]\n",
    "# ratios  = np.array([0.5, 1, 2], keras.backend.floatx())\n",
    "# scales  = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized Anchor Settings:\n",
    "sizes   = [32, 64, 128, 256, 512]\n",
    "strides = [8, 16, 32, 64, 128]\n",
    "ratios  = np.array([0.25, 1, 4], keras.backend.floatx())\n",
    "scales  = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [ratios,scales,sizes,strides] #uncomment to setup anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object that stores backbone information\n",
    "backbone = models.backbone(backbone_name)\n",
    "\n",
    "# make sure keras is the minimum required version\n",
    "check_keras_version()\n",
    "\n",
    "# create the generators\n",
    "train_generator, validation_generator = create_generators(dataset_type, batch_size, config, image_min_side, image_max_side, backbone.preprocess_image)\n",
    "\n",
    "# create the model\n",
    "if snapshot is not None:\n",
    "    print('Loading model, this may take a second...')\n",
    "    model            = models.load_model(snapshot, backbone_name=backbone_name)\n",
    "    training_model   = model\n",
    "    anchor_params    = None\n",
    "    if config and 'anchor_parameters' in config:\n",
    "        anchor_params = parse_anchor_parameters(config)\n",
    "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params)\n",
    "else:\n",
    "    weights = weights\n",
    "    # default to imagenet if nothing else is specified\n",
    "    if weights is None and imagenet_weights:\n",
    "        weights = backbone.download_imagenet()\n",
    "\n",
    "    print('Creating model, this may take a second...')\n",
    "    model, training_model, prediction_model = create_models(\n",
    "        backbone_retinanet=backbone.retinanet,\n",
    "        num_classes=train_generator.num_classes(),\n",
    "        weights=weights,\n",
    "        multi_gpu=multi_gpu,\n",
    "        freeze_backbone=freeze_backbone,\n",
    "        lr=lr,\n",
    "        config=config\n",
    "    )\n",
    "    print('Number of classes = {}'.format(train_generator.num_classes()))\n",
    "\n",
    "# print model summary\n",
    "#print(model.summary())\n",
    "\n",
    "# this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "if 'vgg' in backbone_name or 'densenet' in backbone_name:\n",
    "    train_generator.compute_shapes = make_shapes_callback(model)\n",
    "    if validation_generator:\n",
    "        validation_generator.compute_shapes = train_generator.compute_shapes\n",
    "\n",
    "# create the callbacks\n",
    "callbacks = create_callbacks(\n",
    "    model,\n",
    "    training_model,\n",
    "    prediction_model,\n",
    "    validation_generator,\n",
    "    tensorboard_dir, \n",
    "    evaluation, \n",
    "    dataset_type, \n",
    "    weighted_average, \n",
    "    snapshot, \n",
    "    snapshot_path, \n",
    "    backbone\n",
    ")\n",
    "\n",
    "# Use multiprocessing if workers > 0\n",
    "if workers > 0:\n",
    "    use_multiprocessing = True\n",
    "else:\n",
    "    use_multiprocessing = False\n",
    "\n",
    "if not compute_val_loss:\n",
    "    validation_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start training\n",
    "training_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    workers=workers,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    max_queue_size=max_queue_size,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.save('example.hdf5')\n",
    "\n",
    "f = open('example.json', 'w')\n",
    "model_json = prediction_model.to_json()\n",
    "f.write(model_json)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Model to Inference Model (source_dir, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!keras_retinanet/bin/convert_model.py \\\n",
    "snapshots/example.hdf5 \\\n",
    "snapshots/example_inference.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
