{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adjust this to point to your downloaded/trained model\n",
    "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
    "model_path = os.path.join( 'snapshots', 'example_inference.hdf5')\n",
    "\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "#model = models.convert_model(model)\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'labelName'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(image, box, color, thickness=2):\n",
    "    \"\"\" Draws a box on an image with a given color.\n",
    "\n",
    "    # Arguments\n",
    "        image     : The image to draw on.\n",
    "        box       : A list of 4 elements (x1, y1, x2, y2).\n",
    "        color     : The color of the box.\n",
    "        thickness : The thickness of the lines to draw a box with.\n",
    "    \"\"\"\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.rectangle(image, (b[0], b[1]), (b[2], b[3]), color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "def draw_caption(image, box, caption,):\n",
    "    \"\"\" Draws a caption above the box in an image.\n",
    "\n",
    "    # Arguments\n",
    "        image   : The image to draw on.\n",
    "        box     : A list of 4 elements (x1, y1, x2, y2).\n",
    "        caption : String containing the text to draw.\n",
    "    \"\"\"\n",
    "    b = np.array(box).astype(int)\n",
    "    # cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "    b_y = int((b[1]+b[3])/2)\n",
    "    #cv2.putText(image, caption, (b[0], b_y+j*80), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 0, 0), 3, lineType=cv2.LINE_AA)\n",
    "    #cv2.putText(image, caption, (b[0], b_y+j*80), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (255, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "    cv2.putText(image, caption, (b[0], b_y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "    cv2.putText(image, caption, (b[0], b_y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 255, 255), 1, lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "test_images_path = '' # path to test images\n",
    "test_images = glob.glob(test_images_path + \"*.jpeg\") + glob.glob(test_images_path + \"*.png\") +  glob.glob(test_images_path + \"*.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_images:\n",
    "# load image\n",
    "    image = read_image_bgr(i)\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "    #print(boxes[0].shape,scores[0].shape,labels[0].shape)\n",
    "    selected_indices = tf.image.non_max_suppression( boxes[0], scores[0], max_output_size=300, iou_threshold=0.1)\n",
    "    #selected_indices = selected_indices.eval(session=sess)\n",
    "    selected_boxes = tf.gather(boxes[0], selected_indices)\n",
    "    selected_scores = tf.gather(scores[0], selected_indices)\n",
    "    selected_labels = tf.gather(labels[0], selected_indices)\n",
    "    selected_boxes = selected_boxes.eval(session=tf.Session())\n",
    "    selected_scores = selected_scores.eval(session=tf.Session())\n",
    "    selected_labels = selected_labels.eval(session=tf.Session())\n",
    "    #print(selected_boxes.shape,selected_scores.shape,selected_labels.shape)\n",
    "    # correct for image scale\n",
    "    selected_boxes /= scale\n",
    "    #boxes = non_max_suppression_fast(boxes[0],0.5)    \n",
    "    #boxes /= scale\n",
    "    # visualize detections\n",
    "    for box, score, label in zip(selected_boxes, selected_scores, selected_labels):\n",
    "    #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < 0.5:\n",
    "            break\n",
    "\n",
    "        #color = label_color(label)\n",
    "        color = label_color(label+1)\n",
    "\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color, thickness=2)\n",
    "\n",
    "        caption_ori = \"{:.3f}\".format(score)\n",
    "        #for j, line in enumerate(caption_ori.split('/')): \n",
    "        draw_caption(draw, b, caption_ori,)\n",
    "        \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(draw)\n",
    "    plt.show()\n",
    "    # now save detection results to folder 'testResults'\n",
    "    output_folder = 'testResults'\n",
    "    fp,fn = os.path.split(i)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    plt.imsave(os.path.join(output_folder,'{}'.format(fn)),draw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
